{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fa3c02",
   "metadata": {},
   "source": [
    "## Load the CSV and Inspect Basic Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv('D:/PROJECTS/Version Control/CHATBOT/building-smart-bots-from-scratch/data/Conversation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46443c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3725, 3) rows x columns \n",
      "\n",
      "First 5 rows:\n",
      "    Serial no.                             question   \n",
      "0           0               hi, how are you doing?  \\\n",
      "1           1        i'm fine. how about yourself?   \n",
      "2           2  i'm pretty good. thanks for asking.   \n",
      "3           3    no problem. so how have you been?   \n",
      "4           4     i've been great. what about you?   \n",
      "\n",
      "                                     answer  \n",
      "0             i'm fine. how about yourself?  \n",
      "1       i'm pretty good. thanks for asking.  \n",
      "2         no problem. so how have you been?  \n",
      "3          i've been great. what about you?  \n",
      "4  i've been good. i'm in school right now.  \n"
     ]
    }
   ],
   "source": [
    "# print shape and first few rows\n",
    "print(f\"Dataset shape: {df.shape} rows x columns \\n\")\n",
    "\n",
    "print(\"First 5 rows:\" + \"\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f94ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['Serial no.', 'question', 'answer'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#List column names explicitly\n",
    "\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739df1b",
   "metadata": {},
   "source": [
    "## Check for Missing / NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93167604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts:\n",
      "Serial no.    0\n",
      "question      0\n",
      "answer        0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for any missing values per column\n",
    "\n",
    "print(\"Missing value counts:\")\n",
    "print(df.isna().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fffc5",
   "metadata": {},
   "source": [
    "## Inspect Data Types & Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eddb14d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "Serial no.     int64\n",
      "question      object\n",
      "answer        object\n",
      "dtype: object \n",
      "\n",
      "Unique Serial No: 3725 out of 3725\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes, \"\\n\")\n",
    "\n",
    "# 7. If Serial No exists, is it truly unique?\n",
    "if 'Serial no.' in df.columns:\n",
    "    unique_serials = df['Serial no.'].nunique()\n",
    "    total_rows = df.shape[0]\n",
    "\n",
    "    print(f\"Unique Serial No: {unique_serials} out of {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ef994",
   "metadata": {},
   "source": [
    "## Detect Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68a68b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-row duplicates found: 0\n",
      "No exact full-row duplicates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for exact duplicate rows\n",
    "dup_full = df.duplicated(keep=False)  # marks all rows that have a full duplicate\n",
    "num_dup_full = dup_full.sum()\n",
    "\n",
    "print(f\"Full-row duplicates found: {num_dup_full}\")\n",
    "\n",
    "\n",
    "if num_dup_full > 0:\n",
    "    print(df[dup_full].head(), \"\\n\")\n",
    "else:\n",
    "    print(\"No exact full-row duplicates.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37453eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with duplicate 'question' text: 317\n",
      "      Serial no.                     question   \n",
      "1619        1619               anything else?  \\\n",
      "1583        1583               anything else?   \n",
      "596          596             are you serious?   \n",
      "243          243             are you serious?   \n",
      "1136        1136                are you sure?   \n",
      "3275        3275                are you sure?   \n",
      "2665        2665                are you sure?   \n",
      "1842        1842                are you sure?   \n",
      "474          474  did you go to school today?   \n",
      "422          422  did you go to school today?   \n",
      "\n",
      "                                             answer  \n",
      "1619                             i need a notebook.  \n",
      "1583                       yes. it's not expensive!  \n",
      "596              i haven't heard anything about it.  \n",
      "243                       yes, i am really excited.  \n",
      "1136                             it's almost empty.  \n",
      "3275          we will be house rich, but cash poor.  \n",
      "2665                            of course i'm sure.  \n",
      "1842                 yes. i remember this big tree.  \n",
      "474                             of course. did you?  \n",
      "422   yeah, i went to school today. were you there?   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Are there duplicate Questions? (i.e., same text but maybe different answers)\n",
    "dup_q = df.duplicated(subset=['question'], keep=False)\n",
    "num_dup_q = dup_q.sum()\n",
    "\n",
    "print(f\"Rows with duplicate 'question' text: {num_dup_q}\")\n",
    "\n",
    "\n",
    "if num_dup_q > 0:\n",
    "    print(df[dup_q].sort_values('question').head(10), \"\\n\")\n",
    "else:\n",
    "    print(\"No duplicate Questions.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8e970",
   "metadata": {},
   "source": [
    "## Analyze Text Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f6d12f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question length (chars) stats:\n",
      "Answer length (chars) stats:\n",
      "count    3725.000000\n",
      "mean       32.213154\n",
      "std        14.545945\n",
      "min         3.000000\n",
      "25%        21.000000\n",
      "50%        30.000000\n",
      "75%        41.000000\n",
      "max        97.000000\n",
      "Name: a_len_chars, dtype: float64 \n",
      "\n",
      "5 Longest Questions (chars):\n",
      "                                               question  q_len_chars\n",
      "2634  what if you fall while you're holding the ligh...           97\n",
      "3292  when you're inside, you will always hear cars ...           88\n",
      "3207  i mean, someone used their dirty hands to pick...           88\n",
      "2329  but when i sneak just one cigarette in the mor...           82\n",
      "1812  because you'll have an accident. most accident...           82 \n",
      "\n",
      "5 Shortest Questions (chars):\n",
      "     question  q_len_chars\n",
      "3611      so?            3\n",
      "1294      no.            3\n",
      "3083      oh.            3\n",
      "3289      so?            3\n",
      "947       so?            3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new columns for text lengths (characters)\n",
    "df['q_len_chars'] = df['question'].astype(str).map(len)\n",
    "df['a_len_chars'] = df['answer'].astype(str).map(len)\n",
    "\n",
    "# 11. Basic statistics on lengths\n",
    "print(\"Question length (chars) stats:\")\n",
    "print(\"Answer length (chars) stats:\")\n",
    "print(df['a_len_chars'].describe(), \"\\n\")\n",
    "\n",
    "# 12. (Optional) Sort by longest/shortest question\n",
    "print(\"5 Longest Questions (chars):\")\n",
    "print(df.sort_values('q_len_chars', ascending=False)[['question', 'q_len_chars']].head(), \"\\n\")\n",
    "\n",
    "print(\"5 Shortest Questions (chars):\")\n",
    "print(df.sort_values('q_len_chars', ascending=True)[['question', 'q_len_chars']].head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade931ec",
   "metadata": {},
   "source": [
    "## Quick Vocabulary Check (Most Common Words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f92add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most common words in Questions:\n",
      "i               → 1270\n",
      "you             → 972\n",
      "the             → 764\n",
      "to              → 683\n",
      "it              → 652\n",
      "a               → 634\n",
      "s               → 501\n",
      "that            → 454\n",
      "t               → 391\n",
      "what            → 348\n",
      "do              → 302\n",
      "is              → 262\n",
      "of              → 240\n",
      "and             → 225\n",
      "have            → 218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize (simple whitespace + punctuation split)\n",
    "def tokenize(text):\n",
    "    # Lowercase + split on non-word characters\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", str(text).lower())\n",
    "    return tokens\n",
    "\n",
    "# Build one big list of all question‐tokens\n",
    "all_q_tokens = []\n",
    "for q in df['question'].astype(str):\n",
    "    all_q_tokens.extend(tokenize(q))\n",
    "\n",
    "# Count top 15 most common words\n",
    "counter_q = Counter(all_q_tokens)\n",
    "most_common_q = counter_q.most_common(15)\n",
    "\n",
    "print(\"Top 15 most common words in Questions:\")\n",
    "\n",
    "for word, freq in most_common_q:\n",
    "    print(f\"{word.ljust(15)} → {freq}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5286f",
   "metadata": {},
   "source": [
    "## Spot-Check Weird or Malformed Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1434e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions with non-ASCII chars: 6\n",
      "                                               question\n",
      "858   different thingsÂ—not the same thing all the t...\n",
      "1523     look at the bottom of my shoesÂ—they're clean.\n",
      "2097               \"Â…and you know you should be glad!\"\n",
      "2100                  oh, yes! \"let it be, let it beÂ…\"\n",
      "2328  you don't need a good nose for thatÂ—cigarette... \n",
      "\n",
      "Answers with non-ASCII chars: 13\n",
      "                                                 answer\n",
      "857   different thingsÂ—not the same thing all the t...\n",
      "1522     look at the bottom of my shoesÂ—they're clean.\n",
      "2096               \"Â…and you know you should be glad!\"\n",
      "2099                  oh, yes! \"let it be, let it beÂ…\"\n",
      "2100            \"Â…there will be an answer, let it be!\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detect non-ASCII characters\n",
    "def has_non_ascii(s):\n",
    "    try:\n",
    "        s.encode('ascii')\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "\n",
    "mask_non_ascii_q = df['question'].astype(str).map(has_non_ascii)\n",
    "mask_non_ascii_a = df['answer'].astype(str).map(has_non_ascii)\n",
    "\n",
    "print(f\"Questions with non-ASCII chars: {mask_non_ascii_q.sum()}\")\n",
    "print(df[mask_non_ascii_q][['question']].head(), \"\\n\")\n",
    "\n",
    "print(f\"Answers with non-ASCII chars: {mask_non_ascii_a.sum()}\")\n",
    "print(df[mask_non_ascii_a][['answer']].head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13503fe4",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing\n",
    "\n",
    "####   1. Loads original CSV from ../data/\n",
    "####   2. Renames columns to snake_case\n",
    "####   3. Strips whitespace\n",
    "####   4. Normalizes/removes non-ASCII artifacts\n",
    "####   5. Deduplicates based on 'question' (keeps first)\n",
    "####   6. Lowercases text\n",
    "####   7. Saves to ../data/clean_conversation_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b29d236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# 1) Load original CSV\n",
    "df = pd.read_csv('D:/PROJECTS/Version Control/CHATBOT/building-smart-bots-from-scratch/data/Conversation.csv')\n",
    "\n",
    "# 2) Rename columns to snake_case\n",
    "df = df.rename(columns={'Serial no.': 'serial_no'})\n",
    "\n",
    "# 3) Strip leading/trailing whitespace from question & answer\n",
    "df['question'] = df['question'].astype(str).str.strip()\n",
    "df['answer']   = df['answer'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d23a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Normalize Unicode & remove leftover “Â” artifacts\n",
    "def normalize_text(text):\n",
    "    # Normalize Unicode (NFKD form) \n",
    "    # decomposes characters into ASCII + diacritics\n",
    "    normalized = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Encode to ASCII and ignore non-ASCII (dropping any leftover accent/Â)\n",
    "    ascii_bytes = normalized.encode('ascii', 'ignore')\n",
    "    ascii_str   = ascii_bytes.decode('ascii')\n",
    "    \n",
    "    # Remove any weird control chars or multiple spaces\n",
    "    # (e.g. leftover zero-width spaces, weird punctuation)\n",
    "    ascii_str = re.sub(r'\\s+', ' ', ascii_str)  # collapse multiple whitespace\n",
    "    ascii_str = ascii_str.strip()\n",
    "    \n",
    "    return ascii_str\n",
    "\n",
    "# Apply normalization to all questions & answers\n",
    "df['question'] = df['question'].map(normalize_text)\n",
    "df['answer']   = df['answer'].map(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "510c7d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 duplicate questions. New row count: 3510\n"
     ]
    }
   ],
   "source": [
    "# 5) Deduplicate based on 'question' (keep the FIRST occurrence)\n",
    "#    We saw 317 rows where 'question' text was identical. For a Level-1 rule-based bot,\n",
    "#    we'll keep only the first answer for any duplicated question.\n",
    "\n",
    "df_before = df.shape[0]\n",
    "df = df.drop_duplicates(subset=['question'], keep='first').reset_index(drop=True)\n",
    "\n",
    "df_after = df.shape[0]\n",
    "print(f\"Dropped {df_before - df_after} duplicate questions. New row count: {df_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f457c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Lowercase all text (optional but recommended for TF-IDF matching)\n",
    "df['question'] = df['question'].str.lower()\n",
    "df['answer']   = df['answer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a43c9f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: D:/PROJECTS/Version Control/CHATBOT/building-smart-bots-from-scratch/data/clean_conversation_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 7) Save cleaned CSV for future use\n",
    "\n",
    "output_path = 'D:/PROJECTS/Version Control/CHATBOT/building-smart-bots-from-scratch/data/clean_conversation_dataset.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   serial_no                             question   \n",
      "0          0               hi, how are you doing?  \\\n",
      "1          1        i'm fine. how about yourself?   \n",
      "2          2  i'm pretty good. thanks for asking.   \n",
      "3          3    no problem. so how have you been?   \n",
      "4          4     i've been great. what about you?   \n",
      "\n",
      "                                     answer  \n",
      "0             i'm fine. how about yourself?  \n",
      "1       i'm pretty good. thanks for asking.  \n",
      "2         no problem. so how have you been?  \n",
      "3          i've been great. what about you?  \n",
      "4  i've been good. i'm in school right now.  \n",
      "(3510, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_clean = pd.read_csv('D:/PROJECTS/Version Control/CHATBOT/building-smart-bots-from-scratch/data/clean_conversation_dataset.csv')\n",
    "print(df_clean.head())\n",
    "print(df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c42407f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any non-ASCII in questions? 0\n",
      "Any non-ASCII in answers? 0\n"
     ]
    }
   ],
   "source": [
    "def has_non_ascii(s):\n",
    "    try:\n",
    "        s.encode('ascii')\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "\n",
    "print(\"Any non-ASCII in questions?\", df_clean['question'].map(has_non_ascii).sum())\n",
    "print(\"Any non-ASCII in answers?\",   df_clean['answer'].map(has_non_ascii).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdac13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
